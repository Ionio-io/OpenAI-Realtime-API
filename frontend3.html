<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio Chat</title>
    <style>
        #logBox {
            width: 100%;
            height: 200px;
            overflow-y: scroll;
            border: 1px solid #ccc;
            padding: 10px;
            margin-top: 20px;
        }
        #response {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <h1>Real-time Audio Chat</h1>
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>
    <div id="response"></div>
    <div id="logBox"></div>

    <script>
        let socket;
        let audioContext;
        let processor;
        let microphoneStream;

        let audiochunksQueue = [];

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const responseDiv = document.getElementById('response');
        const logBox = document.getElementById('logBox');

        startBtn.onclick = startRecording;
        stopBtn.onclick = stopRecording;

        function log(message) {
            logBox.innerHTML += `${new Date().toISOString()}: ${message}<br>`;
            logBox.scrollTop = logBox.scrollHeight;
        }

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    microphoneStream = stream;
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    processor = audioContext.createScriptProcessor(1024, 1, 1);

                    source.connect(processor);
                    processor.connect(audioContext.destination);

                    processor.onaudioprocess = function(e) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        const downsampledData = downsampleAudio(inputData, audioContext.sampleRate, 24000);
                        const base64Audio = base64EncodeAudio(downsampledData);
                        if (socket && socket.readyState === WebSocket.OPEN) {
                            socket.send(JSON.stringify({
                                type: 'input_audio_buffer.append',
                                audio: base64Audio
                            }));
                            // log('Sent audio chunk to server');
                        }
                    };

                    startBtn.disabled = true;
                    stopBtn.disabled = false;

                    // Connect to FastAPI WebSocket
                    socket = new WebSocket('ws://localhost:8000/ws/audio');
                    socket.onopen = () => {
                        log('WebSocket connection opened');
                        // Start sending audio data once the connection is open
                        processor.connect(audioContext.destination);
                    };
                    socket.onclose = () => {
                        log('WebSocket connection closed');
                        // Stop processing audio when the connection is closed
                        processor.disconnect();
                    };
                    socket.onerror = (error) => log(`WebSocket error: ${error}`);
                    socket.onmessage = handleServerMessage;
                })
                .catch(error => {
                    log(`Error accessing microphone: ${error}`);
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                });
        }

        function stopRecording() {
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
            }
            startBtn.disabled = false;
            stopBtn.disabled = true;
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.send(JSON.stringify({type: 'input_audio_buffer.commit'}));
                socket.close();
            }
        }

        function handleServerMessage(event) {
            const response = JSON.parse(event.data);
            log(`Received event: ${response.type}`);

            switch (response.type) {
                case 'response.audio_transcript.delta':
                    responseDiv.innerHTML += response.delta;
                    break;
                case 'response.audio.delta':
                    console.log("RECEIVED AUDIO CHUNK", response.event_id);
                    // playAudioChunk(response.delta);
                    audiochunksQueue.push(response.delta);
                    break;
                // Handle other event types as needed
            }
        }

        let audioSourceCounter = 0;
        function playAudioChunk(base64Audio) {
            console.log(`playAudioChunk called. Counter: ${++audioSourceCounter}`);
            console.log(`Base64 audio length: ${base64Audio.length}`);
            
            const audioData = base64ToArrayBuffer(base64Audio);
            console.log(`Audio data byte length: ${audioData.byteLength}`);
            
            const audioBuffer = audioContext.createBuffer(1, audioData.byteLength / 2, 24000);
            const channelData = audioBuffer.getChannelData(0);
            const int16Array = new Int16Array(audioData);
            for (let i = 0; i < int16Array.length; i++) {
                channelData[i] = int16Array[i] / 32768;
            }
            console.log(`Channel data length: ${channelData.length}`);
            
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.start();
            console.log(`Audio playback started. Source ID: ${audioSourceCounter}`);
            
            source.onended = () => {
                console.log(`Audio playback ended. Source ID: ${audioSourceCounter}`);
            };
        }

        let isPlaying = false;

        async function playQueuedAudioChunks() {
            if (isPlaying || audiochunksQueue.length === 0) return;
            
            isPlaying = true;
            
            while (audiochunksQueue.length > 0) {
                const chunk = audiochunksQueue.shift();
                await playAudioChunkPromise(chunk);
            }
            
            isPlaying = false;
        }

        function playAudioChunkPromise(base64Audio) {
            return new Promise((resolve) => {
                console.log(`playAudioChunk called. Counter: ${++audioSourceCounter}`);
                console.log(`Base64 audio length: ${base64Audio.length}`);
                
                const audioData = base64ToArrayBuffer(base64Audio);
                console.log(`Audio data byte length: ${audioData.byteLength}`);
                
                const audioBuffer = audioContext.createBuffer(1, audioData.byteLength / 2, 24000);
                const channelData = audioBuffer.getChannelData(0);
                const int16Array = new Int16Array(audioData);
                for (let i = 0; i < int16Array.length; i++) {
                    channelData[i] = int16Array[i] / 32768;
                }
                console.log(`Channel data length: ${channelData.length}`);
                
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
                console.log(`Audio playback started. Source ID: ${audioSourceCounter}`);
                
                source.onended = () => {
                    console.log(`Audio playback ended. Source ID: ${audioSourceCounter}`);
                    resolve();
                };
            });
        }

        // Start the audio playback loop
        setInterval(playQueuedAudioChunks, 100);

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function downsampleAudio(audioData, originalSampleRate, targetSampleRate) {
            const ratio = originalSampleRate / targetSampleRate;
            const newLength = Math.round(audioData.length / ratio);
            const result = new Float32Array(newLength);
            for (let i = 0; i < newLength; i++) {
                result[i] = audioData[Math.floor(i * ratio)];
            }
            return result;
        }

        function base64EncodeAudio(float32Array) {
            const buffer = floatTo16BitPCM(float32Array);
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const chunkSize = 0x8000; // 32KB chunk size
            for (let i = 0; i < bytes.length; i += chunkSize) {
                let chunk = bytes.subarray(i, i + chunkSize);
                binary += String.fromCharCode.apply(null, chunk);
            }
            return btoa(binary);
        }

        function floatTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            for (let i = 0; i < float32Array.length; i++) {
                let s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7fff, true);
            }
            return buffer;
        }
    </script>
</body>
</html>